---
title: "Bayesian Multilevel Modeling of Retention Data Informed by Structural Similarity of Analytes"
author:
  - name: "Paweł Wiczling*"
    affiliations:
      - name: "Department of Biopharmaceutics and Pharmacodynamics, Medical University of Gdańsk, Gen. J. Hallera 107, 80-416 Gdańsk, Poland"
date: "`r format(Sys.Date())`"
format:
  html:
    theme: cosmo
    toc: true
    code-fold: true  
    code-tools: true
    fig-width: 7
    fig-height: 7
knitr:
  opts_chunk: 
    dev: "ragg_png"
bibliography: references.bib
csl: analytical-chemistry.csl
---


# Introductions

This work focuses on multilevel modeling of isocratic HPLC retention data [@kamedulska_toward_2022,] [@kamedulska_statistical_2022,] [@wiczling_application_2021,] [@kubik_analysis_2018], incorporating structural similarity between analytes. Structural similarity (such as Taniomoto similairty metric) can be easily calculated from SMILES representations and help predicting analyte retention if experimental data of structurally similar analytes is available.

# Setup
```{r setup, message=FALSE}
knitr::opts_chunk$set(cache=TRUE, message=FALSE, error=FALSE, warning=FALSE, comment=NA, out.width='95%')

suppressWarnings(library(dplyr))
suppressWarnings(library(ggplot2))
suppressWarnings(library(patchwork))
suppressWarnings(library(gridExtra))
suppressWarnings(library(naniar))
suppressWarnings(library(knitr))
suppressWarnings(library(data.table))
suppressWarnings(library(tidyverse))
suppressWarnings(library(glue))
suppressWarnings(library(whisker))
suppressWarnings(library(here))
suppressWarnings(library(cmdstanr))
suppressWarnings(library(posterior))
suppressWarnings(library(bayesplot))
suppressWarnings(library(tidybayes))
suppressWarnings(library(reshape2))
suppressWarnings(library(pracma))
suppressWarnings(library(mrgmisc))
suppressWarnings(library(GGally))
suppressWarnings(library(igraph))
suppressWarnings(library(ggraph))
suppressWarnings(library(ggcorrplot))
#remotes::install_github("metrumresearchgroup/mrgmisc")
set_cmdstan_path("C:/Users/GUMed/.cmdstan/cmdstan-2.36.0")
set.seed(10271998)
select<-dplyr::select
source("helper-functions.R")
```

```{r settings}
data_dir = here::here("data")
model_dir <- here::here("model","stan")  
figures_dir <- here::here("deliv","figures", "stan")
tables_dir <- here::here("deliv","tables", "stan")
if(!file.exists(figures_dir)) dir.create(figures_dir, recursive = T)
if(!file.exists(model_dir)) dir.create(model_dir, recursive = T)
if(!file.exists(tables_dir)) dir.create(tables_dir, recursive = T)

data_deliv_dir = here::here("data","deliv")
data_derived_dir = here::here("data","derived")
if(!file.exists(data_deliv_dir)) dir.create(data_deliv_dir, recursive = T)
if(!file.exists(data_derived_dir)) dir.create(data_derived_dir, recursive = T)

figures_eda_dir <- here::here("deliv","figures", "stan")
tables_eda_dir <- here::here("deliv","tables", "stan")
if(!file.exists(figures_eda_dir)) dir.create(figures_eda_dir, recursive = T)
if(!file.exists(tables_eda_dir)) dir.create(tables_eda_dir, recursive = T)
```

# Data

We used a publicly available [dataset](www.retentionprediction.org/hplc/database/) that comprises the measurements of RP-HPLC retention times collected for 1026 analytes. The retention times were measured under isocratic conditions on Eclipse Plus C18 (Agilent) stationary phase with 3.5 μm particles. The experiments were conducted using a mixture of two solvents: solvent A, which was made of 0.1% formic acid in water, and solvent B, which was made of 0.1% formic acid in acetonitrile. The column temperature was set at 35°C. The data were collected by Boswell et al. and were used to create a method to predict retention time by Back-Calculating the Gradient [@BOSWELL20116732, @BOSWELL20116742].

The 2D structures of analytes, Tanimoto similarity matrix, log P and the number of functional groups were calculated using RDkit toolkit [@greg_landrum_2025_15773589]:

[RDKit-based predcitors](functional-groups-rdkit.html "rdkit")

[2D-structures](print-analytes-structures.html "Structures")


The Tanimoto coefficient is a common metric used to assess the structural similarity between molecules in cheminformatics. It quantifies the overlap of structural features, represented as binary fingerprints, between two molecules, with a higher coefficient indicating greater similarity (0 indicates no similarity and 1 indicates identical structures). 

## Load data
```{r load-data, message=FALSE, warning=FALSE}
data <- read.csv(here(data_deliv_dir, "database_logk_1026.csv"), header = TRUE)

analytes_names  <- read.csv(here(data_deliv_dir,"database_logk_1026_analyte_names.csv"), header = TRUE)
analytes_names$Analyte <- iconv(analytes_names$Analyte, from = "", to = "UTF-8", sub = "byte")
analytes_names$Analyte <- str_wrap(analytes_names$Analyte, width = 20)

smiles <- read.csv(here(data_deliv_dir,"smiles1026.smi"), sep = "\t", header = FALSE)
smiles<-smiles %>% rename(ID=V2,smiles=V1) %>% select(ID,smiles)
smiles$smiles[905] = "CN(C1CCCCC1N1CCCC1)C(=O)Cc1ccc(c(c1)Cl)Cl" # remove tartrate moiety 
smiles$smiles[425] = "CC(Cc1ccc(cc1)OCC(=O)O)NCC(c1cccc(c1)Cl)O" # remove Na+ and dissociation
smiles$smiles[501] = "c1ccc(cc1)C1(c2ccccc2)C(=O)NC(=N1)O"
smiles$smiles[401]= "CC(C)(C)c1c(CC(C(=O)[OH])[NH2])c(=O)[nH]o1"
smiles$smiles[686] = "CCCCCCCCCCCCCCCC(=O)OC(CC(=O)[OH])C[N+](C)(C)C"
smiles$smiles[901] = "CCOC(=Nc1c[n+](no1)N1CCOCC1)[OH]"

fg_df = read.csv(file = here(data_deliv_dir,"smarts_functional_groups.csv"), header = TRUE)

descriptor_df <- read.csv(file = here(data_deliv_dir,"descriptor_df.csv"), header = TRUE)

similarity_ltri_rcdk_df <- read.csv(file = here(data_deliv_dir,"similarity_ltri_rcdk.csv"), header = TRUE)
similarity_matrix <- make_similarity_matrix_fun(similarity_ltri_rcdk_df)

# names of dissociated groups at low pH
dissociated_groups <- c(
  # Anions
  "Sulfonic_acid", "Sulfinic_acid", "Sulfenic_acid", "Sulfuric_acid", "Sulfuric_monoester",
  "Phosphonic_acid", "Phosphoric_acid", "Phosphoric_monoester", "Phosphinic_acid",
  "Phosphonous_acid", "Phosphinous_acid", "Carbothioic_acid", "Carbodithioic_acid",
  # Cations
  "Primary_aliph_amine", "Secondary_aliph_amine", "Tertiary_aliph_amine", 
  "Quaternary_aliph_ammonium", "Primary_arom_amine", "Secondary_arom_amine", 
  "Tertiary_arom_amine", "Quaternary_arom_ammonium", "Secondary_mixed_amine", 
  "Tertiary_mixed_amine", "Quaternary_mixed_ammonium", "Oxonium", 
  "Immonium", "Sulfonium", "Phosphonium", "Hetero_N_basic_H", "Hetero_N_basic_no_H", "Amidine", "Guanidine", "Hydrazine", "Hydroxylamine", 
  "Diazonium", "N-Oxide"
)
```

## Prepare data
```{r prepare-data, message=FALSE, warning=FALSE}
data<-data %>% left_join(analytes_names) 

functional_groups = fg_df %>%
  select(where(~ is.character(.) || !all(. == 0, na.rm = TRUE))) %>%
  select(-c(id1,id2, SMILES, Anion, Kation, Ammonium))

functional_groups_names<- colnames(functional_groups)
totalnrgroups <- summarise_each(functional_groups, funs(sum))
```

## Initial estimates
```{r initial-estimates}
init_aprox <- data %>%
  group_by(ID) %>%
  summarise(
    S1 = if_else(n() == 1,-16,polyfit(fi / (1 + 2 * fi), logk, 1)[1]),
    logkw = if_else(n() == 1, polyfit(-16 * fi / (1 + 2 * fi), logk, 0), 
                              polyfit(fi / (1 + 2 * fi), logk, 1)[2]),
    S2 = 2) %>%
  ungroup() %>%
  select(logkw, S2, S1) %>%
  mutate(S1 = -S1 / (1 + 2))
```


# Exploratory data analysis

A series of plots to better understand our data can be found here:

[Exploratory Plots](eda.html "EDA")

# Data analysis

## Model

The logarythm of retention factor ($\small lok_{i,j}$) was modeled using the Neue model [@nikitas_20091737]:

$$
\begin{aligned}
& logk_{i,j}=logkw_{i} - S_{1,i} \cdot (1 + S_{2}) \cdot \varphi_{i,j} / (1 + S_{2} \cdot \varphi_{i,j})
\end{aligned}
$$
where $\small j$ denotes observation, $\small i$ denote analyte, $\small logkw_{i}$ represents logarithm of retention factors extrapolated to 0% of organic modifier content $\small S_{1,i}$ and $\small S2$ are the slopes in the Neue equation. In this parametrization of the Neue equation, $\small S1$ reflects the difference between logarithm of retention factors corresponding to water (0% of organic modifier content) and 100% of organic modifier content as eluents.

The statistical model has the following hierarchical structure:

$$ 
\begin{aligned}
& \log k_{obs_{i,j}} \sim student_t(\nu_{obs},logk_{i,j},\sigma) \\
& R_{i} \sim \text{MN}(\theta_R  + \beta \cdot log P_i +\pi_{R1} \cdot X_{1i}  +\pi_{R2} \cdot X_{2i}, K, \Omega) \\
& \pi_{R1,k} \sim N(0,\kappa_{R1}) \\
& \pi_{R2,k} \sim N(0,\kappa_{R2})
\end{aligned}
$$
where $\small R_i=(logkw_{i}, S_{1,i})$ is a vector of analyte-specific parameters, $\small logk_{i,j}$ corresponds to the above Neue equation, $\small MN$ is a matrix normal distribution, $\small \theta_R$ is a vector of typical values of $\small R_i$, $\small \beta_R$ is a vector of slopes between $\small R_i$ and $\small logP_i$,  $\small \pi_{R,1}$ and  $\small \pi_{R,2}$ is a vector of slopes between $\small R_i$ and functional groups: non-dissociated forms $\small X_{1i}$ and dissociated forms $\small X_{2i}$. In turn, $\small \nu_{obs}$ and $\small \sigma$ is the normality parameters and scale of the residuals, $\small K$ and $\small \Omega$ are the scale matrices for the row and column covariance structures. $\small \Omega$ and $\small K$ were decomposed to:

$$
\begin{aligned}
\Omega_1 = diag(\omega) \cdot LL' \cdot diag(\omega) \\
K = 2*\alpha* (S-0.5)+ (1-\alpha)*I \\
\end{aligned}
$$

where $\small LL'$ denotes correlation a correlation matrix, $\small \omega$ denotes standard deviation for between analyte variability, S is a similarity matrix and I is an Identify matrix. In this work the similarity matrix was simplified assuming S=0 for $\small S<0.5$ (analytes are essentially uncorrelated) and the values of S for $\small S \geq 0.5$ were scaled by alpha using the above equation.

A matrix normal distribution models random matrices, with parameters including a mean matrix and two covariance matrices, one for rows (analytes) and one for columns ($\small logkw$ and $\small S$ parameters). These covariance matrices, denoted here as $\small K$ and $\Omega$, capture the dependencies between rows and columns of the random matrix, respectively. The row covariance can be naturally related to similarity matrix approximating its structure.

## Priors

The priors were specified as follows:

$$ 
\begin{aligned}
& \theta_{logkw} \sim normal(2, 4), \\
& \theta_{S1} \sim normal(4, 2), \\
& \theta_{S2} \sim lognormal(0.693, 0.125), \\
& \nu_{obs} = 7,\\
& \omega_{logkw},\omega_{S1} \sim normal_+(0, 1), \\
& \beta_{logkw} \sim  normal(0.7, 0.125), \\
& \beta_{S1} \sim  normal(0.5, 0.125), \\
& \kappa_{logkw},\kappa_{S1} \sim  normal(0, 0.1), \\
& \sigma \sim normal_+(0,0.05), \\
& \alpha \sim normal(0.5,0.25)T[0,1], \\
& p(LL') \propto LKJ(2) \cdot \Pi_u N(c_u, 0.125), \\
& c_u = [0.75]
\end{aligned}
$$

LKJ(2) ensure that the density is uniform over correlation matrices of order 2 and u denotes the unique lower triangular elements of correlation matrix (<http://srmart.in/informative-priors-for-correlation-matrices-an-easy-approach/>)

# Stan

Multilevel modeling was performed in [Stan software](https://mc-stan.org/) linked with R/ [cmdstanr](https://mc-stan.org/cmdstanr/). For the inference we used 500 iterations, 1000 warmup iterations, and 8 Markov chains. Convergence diagnostics were checked using Gelman−Rubin statistics and trace plots.

### Initialize variables and parameters

```{r stan-setup}
# create Stan data set: data
nObs <- length(data$ID)
nAnalytes <- length(unique(data$ID))
start <- (1:nObs)[!duplicated(data$ID)]
end <- c(start[-1] - 1, nObs)
nK = ncol(functional_groups)

idx_diss = which(functional_groups_names %in% dissociated_groups)
idx_nondiss = which(functional_groups_names %notin% dissociated_groups)

similarity_matrix_corrected <- as.matrix(Matrix::nearPD(similarity_matrix, corr = TRUE)$mat)
similarity_ltri_rcdk_subset<-similarity_to_ltr_fun(similarity_matrix_corrected) %>% filter(similarity>=0.5, row!=col)
uid = unique(c(similarity_ltri_rcdk_subset$row,similarity_ltri_rcdk_subset$col))
nodes <- data.frame(id = uid,label = paste(uid))
edges <- data.frame(from = similarity_ltri_rcdk_subset$row,
                    to = similarity_ltri_rcdk_subset$col, 
                    width = similarity_ltri_rcdk_subset$similarity,
                    label = paste(round(similarity_ltri_rcdk_subset$similarity,2)))
g <- graph_from_data_frame(d = edges, vertices = nodes, directed = FALSE)

nodes$group = cluster_louvain(g)$membership

nodes <- nodes %>% arrange(id)
idx_corelatted = unique(nodes$id)
idx_uncorelatted <- setdiff(unique(similarity_ltri_rcdk_df$row), idx_corelatted)
group = nodes$group

df <- nodes
repeat {
  group_sizes <- df %>% dplyr::count(group, name = "size")
  if (all(group_sizes$size >= 45)) break
  smallest <- group_sizes %>% arrange(size) %>% slice(1:2)
  from <- smallest$group[2]
  to <- smallest$group[1]
  df$group[df$group == from] <- to
}

nodes$group_combined <- as.integer(factor(df$group))

similarity_matrix_corrected[similarity_matrix_corrected<0.5]=0.5
similarity_matrix_corrected <- as.matrix(Matrix::nearPD(similarity_matrix_corrected, corr = TRUE)$mat)

sim_mat_masked <-similarity_matrix_corrected
datastruct <- with(data,
                  list(nAnalytes=length(unique(data$ID)),
                       nAnalytes_corr=length(idx_corelatted),
                       nAnalytes_uncorr=length(idx_uncorelatted),
                       idx_corr = idx_corelatted,
                       idx_uncorr = idx_uncorelatted,
                       nfg_diss = length(idx_diss),
                       nfg_nondiss = length(idx_nondiss),
                       idx_diss = idx_diss,
                       idx_nondiss = idx_nondiss,
                       nObs=length(data$ID),
                       analyte=match(data$ID, unique(data$ID)),
                       fi=data$fi,
                       logPobs=descriptor_df$LogP,
                       nK = nK,
                       fgrp = functional_groups,
                       similarity_x = sim_mat_masked,
                       start = start,
                       end= end,
                       logkobs=logk,
                       group = nodes$group_combined,
                       mGroup = length(unique(nodes$group_combined)),
                       run_estimation=1))

# initialize the values for each variable in each chain:
init <- function(){
  list(   logkwHat  = rnorm(1,2,2),
          S1Hat    = rnorm(1,5,1),
          dlogkwHat  = rnorm(1,-1,0.5),
          dS1Hat    = rnorm(1,0,0.5),
          S2Hat = 2*exp(rnorm(1,0,0.125)),
          beta  = rnorm(2,c(0.7,0.5),c(0.125,0.5)),
          omega = c(1,1)*exp(rnorm(2, 0, 0.5)),
          rho =  matrix(c(1,0.75,0.75,1), nrow=2),
          param_corr = cbind(init_aprox$logkw[idx_corelatted],init_aprox$S1[idx_corelatted]),
          param_uncorr = cbind(init_aprox$logkw[idx_uncorelatted],init_aprox$S1[idx_uncorelatted]),
          alpha = max(0.1,min(0.95,rnorm(1,0.5,0.25))),
          pilogkw = rep(0,nK),
          piS1 = rep(0,nK),
          sdpi = c(0.1,0.1,0.1,0.1)* exp(rnorm(4,0,0.1)),
          sigma  =  0.05*exp(rnorm(1, 0, 0.5))
  )
}
```

### Fitting the model

```{r mod-settings}
model_name <- "mod50"
model_name_ext <- paste0(model_name,".stan")

#' folder shortcuts:
mod_figures_dir <- here::here("deliv", "figures", model_name)
mod_tabels_dir  <- here::here("deliv", "tables", model_name)
mod_model_dir   <- here::here("model", "stan", model_name)
mod_output_dir   <- here::here("model", "stan", model_name, "output")

if (!file.exists(mod_figures_dir)) dir.create(mod_figures_dir)
if (!file.exists(mod_tabels_dir)) dir.create(mod_tabels_dir)
if (!file.exists(mod_model_dir)) dir.create(mod_model_dir)
if (!file.exists(mod_output_dir)) dir.create(mod_output_dir)

modelqg_name <- paste0(model_name,"gq")
modelqg_name_ext <- paste0(modelqg_name,".stan")
modgq_model_dir   <- here::here("model", "stan", modelqg_name)
modgq_output_dir   <- here::here("model", "stan", modelqg_name, "output")

modelll_name <- paste0(model_name,"ll")
modelll_name_ext <- paste0(modelll_name,".stan")
modll_model_dir   <- here::here("model", "stan", modelll_name)
modll_output_dir   <- here::here("model", "stan", modelll_name, "output")

if (!file.exists(modgq_model_dir)) dir.create(modgq_model_dir)
if (!file.exists(modgq_output_dir)) dir.create(modgq_output_dir)
if (!file.exists(modll_output_dir)) dir.create(modll_output_dir)
```

#### Optimization

I've compiled the model using cmdstanr and used optimization for initial testing of the code.

```{r stan-compile, eval = FALSE}
mod50 <- cmdstan_model(here::here(mod_model_dir, model_name_ext), stanc_options = list("O1"))
```

```{r stan-optimize, eval = FALSE}
fit_opt <- mod50$optimize(
  data = datastruct,
  output_dir = mod_output_dir,
  output_basename = "mod50-opt",
  init = init,
  iter=3000
)
```

```{r plots-optimize}
fit_opt <- cmdstanr::as_cmdstan_fit(c(paste0(mod_output_dir,"/",  model_name, "-opt-1.csv")))

fit_opt$print(variables = c("logkwHat","S1Hat","dlogkwHat","dS1Hat","beta","S2Hat","omega","rho[1,2]","sigma","alpha","sdpi"), max_rows=13)

data$logkopt<-fit_opt$mle("logkx")

set.seed(123)
p1<-data %>%
  filter(ID %in% sample(unique(data$ID),12)) %>%
  left_join(analytes_names) %>%
  ggplot(aes(x=fi, y=logk)) + 
  geom_point() + 
  geom_line(aes(x=fi, y=logkopt)) + 
  xlim(0,1)+
  facet_wrap(~Analyte) +
  labs(x = "\u03C6", y = expression(logk)) + 
  theme_gray(base_size = 14) + 
  theme(legend.position="none", 
        axis.text =element_text(size = 8),
        strip.text =element_text(size = 8))

p1
```

#### Local sampling (not used)

```{r stan-sample, eval = FALSE}
 fit <- mod50$sample(
   data = datastruct,
   output_dir = mod_output_dir,
   output_basename = "mod50-loc",
   init = init,
   iter_warmup = 1000,
   iter_sampling = 1000,
   chains = 4,
   parallel_chains = 4,
   refresh = 100,
   adapt_delta=0.9
 )
```

#### Tryton

Computations were carried out at the Academic Computer Center in Gdańsk, [Tryton Cluster](https://docs.task.gda.pl/kdm/zasoby-sprzetowe/tryton/).

1. dump the necessary data to .json format

```{r dump-files, eval = FALSE}
write_stan_json(datastruct, paste0(mod_model_dir,"/standata.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-1.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-2.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-3.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-4.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-5.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-6.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-7.json"), always_decimal = FALSE)
write_stan_json(init(), paste0(mod_model_dir,"/init-8.json"), always_decimal = FALSE)
```

2.  run the model using the batch file:

```{=html}
<pre> 
#!/bin/bash -l

#SBATCH --job-name=cmdstan_conda
#SBATCH -N 1
#SBATCH -n 8
#SBATCH -p batch
#SBATCH --time=12:00:00
#SBATCH --mem=2gb 

# load
module load trytonp/cmdstan/2.34.1

export STAN_THREADS=false

# model name
export CMDSTAN_MODEL_NAME="mod50cv"

# paths
export MODEL_SRC_DIR="/users/project1/pt01268/izo50cv"
cd ${CMDSTAN_DIR}

# build/compile
[ -f ${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} ] && echo "Model " ${CMDSTAN_MODEL_NAME} " exists." || make STANCFLAGS=--O1 ${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME}

wait

cd ${MODEL_SRC_DIR}

${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-1.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-1.csv &
${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-2.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-2.csv &
${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-3.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-3.csv &
${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-4.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-4.csv &
${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-5.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-5.csv &
${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-6.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-6.csv &
${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-7.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-7.csv &
${MODEL_SRC_DIR}/${CMDSTAN_MODEL_NAME} sample num_samples=500 num_warmup=1000 algorithm=hmc engine=nuts max_depth=10 stepsize=0.01 adapt delta=0.9 data file=$MODEL_SRC_DIR/standata.json init=$MODEL_SRC_DIR/init-8.json  output file=$MODEL_SRC_DIR/${CMDSTAN_MODEL_NAME}-8.csv &
wait
</pre>
```

3.  loaded the output files using cmdstanr::as_cmdstan_fit: 

```{r stan-load}
fit <- cmdstanr::as_cmdstan_fit(c(
                                  paste0(mod_output_dir,"/",  model_name, "-1.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-2.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-3.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-4.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-5.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-6.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-7.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-8.csv")
                                ))
```

4.  check the diagnostics of samples based on the Stan documentation described herein [diagnose](https://mc-stan.org/docs/cmdstan-guide/diagnose.html)

```{r stan-diagnose, eval = FALSE}
 #fit$cmdstan_diagnose()
 setwd(mod_output_dir)
 str = paste0(cmdstan_path(), '/bin/diagnose  mod50-1.csv mod50-2.csv mod50-3.csv mod50-4.csv mod50-5.csv mod50-6.csv mod50-7.csv mod50-8.csv')
 system(str,intern=TRUE)
```

Output is copied here to save time.

```{=html}
<pre>
 [1] "Checking sampler transitions treedepth."        
 [2] "Treedepth satisfactory for all transitions."      
 [4] "Checking sampler transitions for divergences."  
 [5] "No divergent transitions found."  [7] "Checking E-BFMI - sampler transitions HMC potential energy."
 [8] "E-BFMI satisfactory."                       
[10] "Rank-normalized split effective sample size satisfactory for all parameters."
[12] "The following parameters had rank-normalized split R-hat greater than 1.01:" 
[13] "  S2Hat, param_corr[252,1], param_corr[328,1], param_corr[405,1], param_corr[530,1], param_corr[328,2], param_corr[405,2], param_uncorr[14,1], logkx[621], logkx[622], logkx[2346], logkx[2347], logkx[2864], logkx[3365], logkx[3366], logkx[4237], logkx[4238], param[95,1], param[394,1], param[510,1], param[626,1], param[832,1], param[510,2], param[626,2], lprior"
[14] "Such high values indicate incomplete mixing and biased estimation."  
[15] "You should consider regularizating your model with additional prior information or a more effective parameterization."
</pre>
```

### Genereted quantitites

Most of the quantities of interest were generated using generate_quantities method from a fitted model without re-running the sampler.

```{r generete-quntities, eval=FALSE}
mod50gq <- cmdstan_model(here(modgq_model_dir,modelqg_name_ext))
fitgq  <- mod50gq$generate_quantities(fit,
                                          data = datastruct,
                                          seed = 123,
                                          parallel_chains = 8,
                                          output_dir = modgq_output_dir,
                                          output_basename = modelqg_name)
```

#### Load Results
```{r eta-load}
x <- cmdstanr::read_cmdstan_csv(c(
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-1.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-2.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-3.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-4.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-5.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-6.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-7.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-8.csv")
                                ))
draws_gen_df <- as_draws_df(x$generated_quantities)

#draws_gen_df <- as_draws_df(fitgq$draws())
```

#### Loo
```{r ll-generete-quntities, eval=FALSE}
mod50ll <- cmdstan_model(here(modll_model_dir,modelll_name_ext))
fitll  <- mod50ll$generate_quantities(fit,
                                          data = datastruct,
                                          seed = 123,
                                          parallel_chains = 8,
                                          output_dir = modll_output_dir,
                                          output_basename = modelll_name)

# x <- cmdstanr::read_cmdstan_csv(c(
#                                   paste0(modll_output_dir, "/",  modelll_name, "-1.csv"),
#                                   paste0(modll_output_dir, "/",  modelll_name, "-2.csv"),
#                                   paste0(modll_output_dir, "/",  modelll_name, "-3.csv"),
#                                   paste0(modll_output_dir, "/",  modelll_name, "-4.csv"),
#                                   paste0(modll_output_dir, "/",  modelll_name, "-5.csv"),
#                                   paste0(modll_output_dir, "/",  modelll_name, "-6.csv"),
#                                   paste0(modll_output_dir, "/",  modelll_name, "-7.csv"),
#                                   paste0(modll_output_dir, "/",  modelll_name, "-8.csv")
#                                 ))
# 
# draws_gen_ll_df <- as_draws_df(x$generated_quantities)

res50<-loo::loo(fitll$draws("log_lik"))
res50
```

# Summary of model parameters (table):

The [stansummary](https://mc-stan.org/docs/cmdstan-guide/stansummary.html) function was used to report summary and diagnostic statistics over model parameters. 

```{r summary}
fit$print(variables = c("logkwHat","S1Hat","dlogkwHat","dS1Hat","beta","S2Hat","omega","rho[1,2]","sigma","alpha","sdpi"), max_rows=15)
```

# Trace plots

Trace plots are time series plots of Markov chains. Here we show standard trace plots for several parameters

```{r trace-plots, include=TRUE}
bayesplot::mcmc_trace(fit$draws(c("logkwHat","S1Hat","beta","S2Hat"))) 
bayesplot::mcmc_trace(fit$draws(c("omega","rho[1,2]","sigma","sdpi"))) 
```

# Summary of model parameters (figures)

```{r mcmc-intervals}
p1 <- mcmc_intervals(fit$draws(c("logkwHat","S1Hat","dlogkwHat","dS1Hat","beta[1]","beta[2]","S2Hat","alpha")), point_size = 1)+ scale_y_discrete(labels = c( "logkwHat"= expression(theta[logkw]),
                              "S1Hat"= expression(theta[S1]),
                              "dlogkwHat"=expression(theta[dlogkw]),
                              "dS1Hat"=expression(theta[dS1]),
                              "beta[1]"= expression(beta[logkw]),
                              "beta[2]"= expression(beta[S1]),
                              "S2Hat"=expression(theta[S2]),
                              "alpha"=expression(alpha)),
                   limits = t(rev(c("logkwHat",
                               "S1Hat",
                               "dlogkwHat",                    
                               "dS1Hat",
                               "beta[1]",
                               "beta[2]",
                               "S2Hat",
                               "alpha"))))

p2 <- mcmc_intervals(fit$draws(c("omega[1]","omega[2]", "rho[1,2]", "sigma","sdpi[1]","sdpi[2]","sdpi[3]","sdpi[4]")), point_size = 1) +
  scale_y_discrete(labels = c("omega[1]"=expression(omega[logkw]),
                              "omega[2]"=expression(omega[S1]),
                              "rho[1,2]"= expression(rho["1,2"]),
                              "sigma"= expression(sigma),
                              "sdpi[1]"= expression(paste(kappa*"1"[logkw])), 
                              "sdpi[2]"= expression(paste(kappa*"1"[S1])),
                              "sdpi[3]"= expression(paste(kappa*"2"[logkw])),
                              "sdpi[4]"= expression(paste(kappa*"2"[S1]))),
                   limits = t(rev(c("omega[1]",
                               "omega[2]",
                               "rho[1,2]",
                               "sigma",                    
                               "sdpi[1]",
                               "sdpi[2]",
                               "sdpi[3]",
                               "sdpi[4]"))))

print(p1+p2)
figure_1 = (p1 + 
  theme(
  axis.text.x = element_text(size = 7),
  axis.text.y = element_text(size = 7)))+
  (p2+ 
  theme(
  axis.text.x = element_text(size = 7),
  axis.text.y = element_text(size = 7)))
```

# Summary of functional groups effects (figures)
```{r functinoal-group-effects}
#| fig-width: 6
#| fig-height: 12

idx1 <- which(totalnrgroups > 10)
idx2 <- which(totalnrgroups <= 10)

draws_df_subset <- fit$draws(format = "df", variable = c("pilogkw","piS1"))

param1<-draws_df_subset %>%
  tidybayes::spread_draws(pilogkw[No])%>%
  ggdist::median_qi(pilogkw) %>%
  mutate(param = "pilogkw") %>%
  rename(dv=pilogkw)%>%
  mutate(functional_groups_name = functional_groups_names) 

param2<-draws_df_subset %>%
  tidybayes::spread_draws(piS1[No])%>%
  ggdist::median_qi(piS1) %>%
  mutate(param = "piS1")%>%
  rename(dv=piS1)%>%
  mutate(functional_groups_name = functional_groups_names)

param<-rbind(param1,param2) %>%
  filter(functional_groups_name %in% functional_groups_names[idx1])

p_common <- param %>%
  mutate(functional_groups_name = factor(functional_groups_name, levels = functional_groups_names)) %>%
  ggplot(aes(y = functional_groups_name, x = dv, xmin = .lower, xmax = .upper)) +
  tidybayes::geom_pointinterval(size = 0.5, fatten = 1, linewidth = 0.4) +
  labs(x="Effect", y="Functional group")+
  facet_wrap(. ~ param,
           labeller = labeller(param = as_labeller(c(
             pilogkw = "pi[logkw]",
             piS1 = "pi[S1]"
           ), label_parsed)))+
  geom_vline(xintercept = 0,color = "blue", linetype = "dotted")

param1<-draws_df_subset %>%
  tidybayes::spread_draws(pilogkw[No])%>%
  ggdist::median_qi(pilogkw) %>%
  mutate(param = "pilogkw") %>%
  rename(dv=pilogkw)%>%
  mutate(functional_groups_name = functional_groups_names) 

param2<-draws_df_subset %>%
  tidybayes::spread_draws(piS1[No])%>%
  ggdist::median_qi(piS1) %>%
  mutate(param = "piS1")%>%
  rename(dv=piS1)%>%
  mutate(functional_groups_name = functional_groups_names)

param<-rbind(param1,param2) %>%
  filter(functional_groups_name %in% functional_groups_names[idx2])

p_uncommon <- param %>%
  mutate(functional_groups_name = factor(functional_groups_name, levels = functional_groups_names)) %>%
  ggplot(aes(y = functional_groups_name, x = dv, xmin = .lower, xmax = .upper)) +
  tidybayes::geom_pointinterval(size = 0.5, fatten = 1, linewidth = 0.4) +
  labs(x="Effect", y="Functional group")+
  facet_wrap(. ~ param,
           labeller = labeller(param = as_labeller(c(
             pilogkw = "pi[logkw]",
             piS1 = "pi[S1]"
           ), label_parsed)))+
  geom_vline(xintercept = 0,color = "blue", linetype = "dotted")

p_uncommon 
p_common

figure_2<-(p_common+ 
 theme(
  axis.title.x = element_text(size = 8),
  axis.title.y = element_text(size = 8),
  axis.text.x = element_text(size = 4),
  axis.text.y = element_text(size = 4)))
figure_S2<-(p_uncommon+ 
theme(
  axis.title.x = element_text(size = 8),
  axis.title.y = element_text(size = 8),
  axis.text.x = element_text(size = 4),
  axis.text.y = element_text(size = 4)))

```

# Fits

```{r ind-pop-gof-plots}
results_ind <-draws_gen_df %>%
  slice_sample(n=200) %>%
  tidybayes::spread_draws(slogk_ind[i]) %>% 
  rename(ID=i) %>%
  group_by(ID)%>%
  tidybayes::median_qi(logkpred = slogk_ind) %>%
  select(-ID)

results_pop <-draws_gen_df %>%
  slice_sample(n=200) %>%
  tidybayes::spread_draws(slogk_pop[i]) %>% 
  rename(ID=i) %>%
  group_by(ID)%>%
  tidybayes::median_qi(logkpred = slogk_pop) %>%
  select(-ID)

p1 = data%>%
  cbind(results_ind) %>%
  ggplot(aes(x=logkpred, y=logk)) + 
  geom_point() + 
  #geom_errorbar(aes(xmin = .lower, xmax = .upper), width=0.01)+
  geom_abline(intercept = 0, slope = 1) +
  labs(x = "logk (individual)", y = "logk (observed)") +
  theme_gray(base_size = 14) + 
  theme(legend.position="none")

p2 = data%>%
  cbind(results_pop) %>%
  ggplot(aes(x=logkpred, y=logk)) + 
  geom_point() + 
  #geom_errorbar(aes(xmin = .lower, xmax = .upper), width=0.01)+
  geom_abline(intercept = 0, slope = 1) +
  labs(x = "logk (population)", y = "logk (observed)") + 
  theme_gray(base_size = 14) + 
  theme(legend.position="none")

figure_S3 <- p1+p2
```


```{r ind-predictions}

analytes_idx = c(1:9, 501,510, 626)

p <-draws_gen_df %>%
  slice_sample(n=1000) %>%
  tidybayes::spread_draws(sparam_ind[i,..], sS2Hat) %>%
  rename(ID=i) %>%
  left_join(analytes_names) %>%
  filter(ID %in% analytes_idx) %>%
  tidyr::expand_grid(fi = seq(0,1,0.1)) %>%
  mutate(logk = sparam_ind.1-sparam_ind.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  ggplot(aes(x = fi, y = logk)) +
  ggdist::stat_lineribbon(.width = c(.90), alpha = 1/2) +
  geom_point(data = filter(data,ID %in% analytes_idx),aes(x=fi, y=logk)) + 
  facet_wrap(~Analyte)+
  labs(x="\u03C6", y="logk (individual)") +
  theme(legend.position = "none") +
  coord_cartesian(xlim=c(0,1),ylim=c(-1,2))

print(p)
```

```{r pop-predictions}
analytes_idx = c(1:9, 501,510, 626)

p <-draws_gen_df %>%
  slice_sample(n=1000) %>%
  tidybayes::spread_draws(sparam_pop[i,..], sS2Hat) %>%
  rename(ID=i) %>%
  left_join(analytes_names) %>%
  filter(ID %in% analytes_idx) %>%
  tidyr::expand_grid(fi = seq(0,1,0.1)) %>%
  mutate(logk = sparam_pop.1-sparam_pop.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  ggplot(aes(x = fi, y = logk)) +
  ggdist::stat_lineribbon(.width = c(.90), alpha = 1/2) +
  geom_point(data = filter(data,ID %in% analytes_idx),aes(x=fi, y=logk)) + 
  facet_wrap(~Analyte)+
  labs(x="\u03C6", y="logk (population)") +
  theme(legend.position = "none") +
  coord_cartesian(xlim=c(0,1),ylim=c(-1,2))

print(p)
```


```{r pop-predictions-vpc}
p <-draws_gen_df %>%
  slice_sample(n=1000) %>%
  tidybayes::spread_draws(sparam_pop[i,..], sS2Hat) %>%
  rename(ID=i) %>%
  left_join(analytes_names) %>%
  tidyr::expand_grid(fi = seq(0,1,0.1)) %>%
  mutate(logk = sparam_pop.1-sparam_pop.2*(1+sS2Hat)*fi/(1+sS2Hat*fi))%>%
  mutate(draw=.draw)%>%
  group_by(draw, fi)%>%
  summarise(mlogk = mean(logk),
            llogk = quantile(logk, prob=0.05),
            ulogk = quantile(logk, prob=0.95))%>%
  group_by(fi)%>%
  summarise(mmlogk = mean(mlogk),
            mllogk = quantile(llogk, prob=0.05),
            mulogk = quantile(ulogk, prob=0.95))%>%
  ggplot() +
  geom_line(aes(x = fi, y = mmlogk))+
  geom_line(aes(x = fi, y = mllogk))+
  geom_line(aes(x = fi, y = mulogk))+
  geom_point(data=data,aes(x=fi, y=logk)) + 
  labs(x="\u03C6", y="logk (population)") +
  theme(legend.position = "none") 

print(p)
```

# Individual Parameters and etaplots

Individual parameter are the analyte-specific parameters estimated by the model. The following plots allow to assess the correlations between these parameters.

## Individual parameters

```{r iparam}
param <- draws_gen_df %>%
  select(starts_with("sparam_ind")) %>%
  summarise(across(.fns = mean)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value")

param1 <- param$value[1:nAnalytes]
param2 <- param$value[(nAnalytes+1):(2*nAnalytes)]

data_to_plot_param <- cbind(param1,param2, param1-param2, datastruct$logPobs)
colnames(data_to_plot_param) <- c(expression('logkwN'[i]),expression('S1mN'[i]),expression('logka'[i]), expression('logP'[i]))

p<-ggpairs(as.data.frame(data_to_plot_param), columnLabels = colnames(data_to_plot_param) ,
        labeller = "label_parsed",upper = list(continuous = "points"))

print(p)
figure_S4 <- p
```

## Etas
```{r ieta}
param <- draws_gen_df %>%
  select(starts_with("seta_ind")) %>%
  summarise(across(.fns = mean)) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "value")

param1 <- param$value[1:nAnalytes]
param2 <- param$value[(nAnalytes+1):(2*nAnalytes)]

data_to_plot_param <- cbind(param1,param2,param1-param2,datastruct$logPobs)
colnames(data_to_plot_param) <- c(expression('etalogkwN'[i]),expression('etaS1mN'[i]),expression('etalogka'[i]),expression('logP'[i]))

p<-ggpairs(as.data.frame(data_to_plot_param), columnLabels = colnames(data_to_plot_param) ,
        labeller = "label_parsed",upper = list(continuous = "points"))

print(p)

figure_S5 <- p
```

## Effect of functional groups (screening)
```{r effect-fg-screening}

valid_indices <- which(totalnrgroups > 10)

plots <- map(valid_indices, function(i) {
  # Extract functional group as a factor
  nrgroups <- as.factor(functional_groups[, i])
  
  # Create data frame for plotting
  data_to_plot_fungr <- data.frame(
    param1 = param1,
    param2 = param2,
    param3= param1-param2,
    nrgroups = nrgroups
  )
  
  data_to_plot_fungr %>%
    pivot_longer(cols = c(param1, param2, param3), 
                 names_to = "name", 
                 values_to = "count") %>%
    mutate(etaname = recode(name, 
                           param1 = "etalogkw", 
                           param2 = "etaS",
                           param3 = "etalogka")) %>%
    ggplot(aes(y = count, x = nrgroups)) +
    geom_boxplot() +
    facet_wrap(~etaname) +
    labs(title = functional_groups_names[i], 
         x = "Nr of functional groups", 
         y = "eta")+
  theme(title=element_text(size = 8),
        axis.text =element_text(size = 8),
        strip.text =element_text(size = 8))
})


plot_groups <- split(plots, ceiling(seq_along(plots) / 4))

# Print each group of up to four plots
walk(plot_groups, function(group) {
  combined_plot <- wrap_plots(group, ncol = 2, nrow = 2)
  print(combined_plot)
})
```

# Posterior correlations
```{r posterior-correlations}
etas <- draws_gen_df %>%
  select(starts_with("seta_ind"))
etas_subset <- etas[, grepl("\\[\\d+,1\\]", names(etas))]
cor_matrix <- cor(etas_subset, use = "complete.obs")  # exclude .draw column

etas_decor <- draws_gen_df %>%
  select(starts_with("seta_decorr_ind"))
etas_decor_subset <- etas_decor[, grepl("\\[\\d+,1\\]", names(etas_decor))]
cor_matrix_decorrelated <- cor(etas_decor_subset, use = "complete.obs")  # exclude .draw column

rownames(cor_matrix) <- 1:1026
colnames(cor_matrix) <- 1:1026
rownames(cor_matrix_decorrelated) <- 1:1026
colnames(cor_matrix_decorrelated) <- 1:1026

p1 =similarity_to_ltr_fun(cor_matrix)%>%
  rename(corr = similarity) %>%
  left_join(similarity_ltri_rcdk_df) %>%
  filter(row!=col) %>%
  filter(col %in% row) %>%
  ggplot(aes(y = corr, x = similarity)) +
  geom_hex() +
  scale_fill_viridis_c(option = "G", direction  = -1)+
  theme_minimal() + 
  labs(y = expression(eta*" correlations"),
       x = element_blank()) +
  theme(legend.position = "none")+
  ylim(-1, 1)

p2 =similarity_to_ltr_fun(cor_matrix_decorrelated)%>%
  rename(corr = similarity) %>%
  left_join(similarity_ltri_rcdk_df) %>%
  filter(row!=col) %>%
  filter(col %in% row) %>%
  ggplot(aes(y = corr, x = similarity)) +
    geom_hex() +
  scale_fill_viridis_c(option = "G", direction  = -1)+
  theme_minimal() +  # cleaner theme
  labs(y = expression(eta*" correlations (decorelated)"),
       x = "Tanimoto Similarity") +
  theme(legend.position = "none")+
  ylim(-1, 1)

# p3=similarity_to_ltr_fun(cor_matrix)%>%
#   rename(corr = similarity) %>%
#   left_join(similarity_to_ltr_fun(similarity_matrix_corrected)) %>%
#   filter(row!=col) %>%
#   left_join(nodes%>%rename(row=id)) %>%
#   mutate(group_combined = if_else(is.na(group_combined),0,group_combined))%>%
#   group_by(group_combined) %>%
#   filter(col %in% row) %>%
#   mutate(groups_joined = case_when( group_combined == 0 ~ "Uncorrelated",
#                                     group_combined == 1 ~ "Group 1",
#                                     group_combined == 2 ~ "Group 2",
#                                     group_combined == 3 ~ "Group 3",
#                                     group_combined == 4 ~ "Group 4",
#                                     group_combined == 5 ~ "Group 5",
#                                     group_combined == 6 ~ "Group 6",
#                                     group_combined == 7 ~ "Group 7",
#                                     group_combined == 8 ~ "Group 8",
#                                     group_combined == 9 ~ "Group 9",
#                                     group_combined == 10 ~ "Group 10",
#                                     .default = "other"
#                                     )) %>%
#   ggplot(aes(y = corr, x = similarity, color = factor(group))) +
#   geom_point(alpha = 0.3, size = 1) +
#   theme_minimal() +  # cleaner theme
#   labs( y = "Correlations",
#        x = "Similarity") +
#   theme(legend.position = "none")+
#   facet_wrap(~groups_joined)
# 
# print(p3)
# 
# 
# p4=similarity_to_ltr_fun(cor_matrix_decorrelated)%>%
#   rename(corr = similarity) %>%
#   left_join(similarity_to_ltr_fun(similarity_matrix_corrected)) %>%
#   filter(row!=col) %>%
#   left_join(nodes%>%rename(row=id)) %>%
#   mutate(group_combined = if_else(is.na(group_combined),0,group_combined))%>%
#   group_by(group_combined) %>%
#   filter(col %in% row) %>%
#   mutate(groups_joined = case_when( group_combined == 0 ~ "Uncorrelated",
#                                     group_combined == 1 ~ "Group 1",
#                                     group_combined == 2 ~ "Group 2",
#                                     group_combined == 3 ~ "Group 3",
#                                     group_combined == 4 ~ "Group 4",
#                                     group_combined == 5 ~ "Group 5",
#                                     group_combined == 6 ~ "Group 6",
#                                     group_combined == 7 ~ "Group 7",
#                                     group_combined == 8 ~ "Group 8",
#                                     group_combined == 9 ~ "Group 9",
#                                     group_combined == 10 ~ "Group 10",
#                                     .default = "other"
#                                     )) %>%
#   ggplot(aes(y = corr, x = similarity, color = factor(group))) +
#   geom_point(alpha = 0.3, size = 1) +
#   theme_minimal() +  # cleaner theme
#   labs(y = "Correlations (decorelated)",
#        x = "Similarity") +
#   theme(legend.position = "none")+
#   facet_wrap(~groups_joined)
# 
# print(p4)

p1/p2


figure_3 = (p1+theme(
  axis.title.x = element_text(size = 8),
  axis.title.y = element_text(size = 8),
  axis.text.x = element_text(size = 6),
  axis.text.y = element_text(size = 6)))/
  (p2+theme(
  axis.title.x = element_text(size = 8),
  axis.title.y = element_text(size = 8),
  axis.text.x = element_text(size = 6),
  axis.text.y = element_text(size = 6))) +
  plot_annotation(tag_levels = 'A');
```

::: {.panel-tabset}

## Part 1
```{r part1}
ggcorrplot(similarity_matrix[001:100,001:100])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[001:100,001:100])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[001:100,001:100])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 2
```{r part2}
ggcorrplot(similarity_matrix[101:200,101:200])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[001:100,001:100])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[001:100,001:100])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 3
```{r part3}
ggcorrplot(similarity_matrix[201:300,201:300])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[201:300,201:300])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[201:300,201:300])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 4
```{r part4}
ggcorrplot(similarity_matrix[301:400,301:400])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[301:400,301:400])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[301:400,301:400])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 5
```{r part5}
ggcorrplot(similarity_matrix[401:500,401:500])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[401:500,401:500])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[401:500,401:500])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 6
```{r part6}
ggcorrplot(similarity_matrix[501:600,501:600])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[501:600,501:600])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[501:600,501:600])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 7
```{r part7}
ggcorrplot(similarity_matrix[601:700,601:700])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[601:700,601:700])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[601:700,601:700])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 8
```{r part8}
ggcorrplot(similarity_matrix[701:800,701:800])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[701:800,701:800])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[701:800,701:800])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 9
```{r part9}
ggcorrplot(similarity_matrix[801:900,801:900])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[801:900,801:900])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[801:900,801:900])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

## Part 10
```{r part10}
ggcorrplot(similarity_matrix[901:1026,901:1026])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix[901:1026,901:1026])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
ggcorrplot(cor_matrix_decorrelated[901:1026,901:1026])+
  scale_fill_gradientn(colors = c("white", "gray", "red"), limits = c(0, 1))
```

:::

## Conditional covariance

```{r}
# Function to calculate conditional covariance matrix of X_{2,:} | X_{1,:}
# U: 2x2 row covariance matrix
# V: 2x2 column covariance matrix
conditional_covariance <- function(U, V) {
  u11 <- U[1, 1]
  u12 <- U[1, 2]
  u22 <- U[2, 2]
  scalar <- u22 - (u12^2 / u11)
  cond_cov <- scalar * V
  return(cond_cov)
}

similarity = 1
U <- matrix(c(1, 2*0.71*(similarity-0.5), 2*0.71*(similarity-0.5), 1), nrow = 2, ncol = 2)
V <- matrix(c(1.41^2, 0.88*1.41*1.13, 0.88*1.41*1.13, 1.13^2), nrow = 2, ncol = 2)

# Calculate conditional covariance
result <- conditional_covariance(U, V)
rho = cov2cor(result)[2,1]
sd  = sqrt(diag(result))[2]

var_base = 1.13^2*(1-0.88^2)
var_full = sd^2*(1-rho^2)

(var_base-var_full)/var_base

```

# Effect of similairty

Predict retention times for a set of analytes based on their similarity to other analytes and studied descriptors.

```{r datastruct-cv}
set.seed(123)
foo = nodes
idx <- foo %>%
  group_by(group) %>%
  mutate(N=n()) %>%
  sample_frac(0.1) %>% pull(id)

datastructcv = datastruct;
initcv=init;

idx_analytes_out = sort(idx)
idx_analytes_in = setdiff(unique(datastructcv$analyte),idx_analytes_out)

datax <-  jsonlite::fromJSON(here("model/stan/mod50cv/standata.json"))
which(unique(datax$analyte) %notin% unique(datax$analyte[datax$idxcv]))
idx_analytes_out = which(unique(datax$analyte) %notin% unique(datax$analyte[datax$idxcv]))
idx_analytes_in = which(unique(datax$analyte) %in% unique(datax$analyte[datax$idxcv]))

idxcv =  which(datastructcv$analyte %in% idx_analytes_in)
nObscv = length(idxcv);
datastructcv$idxcv = idxcv;
datastructcv$nObscv = nObscv;
```

## Fitting the model

```{r mod-settings-cv}
model_name <- "mod50cv"
model_name_ext <- paste0(model_name,".stan")

#' folder shortcuts:
mod_figures_dir <- here::here("deliv", "figures", model_name)
mod_tabels_dir  <- here::here("deliv", "tables", model_name)
mod_model_dir   <- here::here("model", "stan", model_name)
mod_output_dir   <- here::here("model", "stan", model_name, "output")

if (!file.exists(mod_figures_dir)) dir.create(mod_figures_dir)
if (!file.exists(mod_tabels_dir)) dir.create(mod_tabels_dir)
if (!file.exists(mod_model_dir)) dir.create(mod_model_dir)
if (!file.exists(mod_output_dir)) dir.create(mod_output_dir)

modelqg_name <- paste0(model_name,"gq")
modelqg_name_ext <- paste0(modelqg_name,".stan")
modgq_model_dir   <- here::here("model", "stan", modelqg_name)
modgq_output_dir   <- here::here("model", "stan", modelqg_name, "output")

if (!file.exists(modgq_model_dir)) dir.create(modgq_model_dir)
if (!file.exists(modgq_output_dir)) dir.create(modgq_output_dir)
```

```{r stan-compile-cv, eval = FALSE}
mod50cv <- cmdstan_model(here::here(mod_model_dir, model_name_ext), stanc_options = list("O1"))
```

```{r dump-files-cv, eval = FALSE}
write_stan_json(datastructcv, paste0(mod_model_dir,"/standata.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-1.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-2.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-3.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-4.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-5.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-6.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-7.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-8.json"), always_decimal = FALSE)
```

```{r stan-load-cv}
fitcv <- cmdstanr::as_cmdstan_fit(c(
                                  paste0(mod_output_dir,"/",  model_name, "-1.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-2.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-3.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-4.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-5.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-6.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-7.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-8.csv")
                                ))
```

## Genereted quantitites

```{r generete-quntities-cv, eval=FALSE}
mod50cvgq <- cmdstan_model(here(modgq_model_dir,modelqg_name_ext))
fitcvgq  <- mod50cvgq$generate_quantities(fitcv,
                                          data = datastructcv,
                                          seed = 123,
                                          parallel_chains = 8,
                                          output_dir = modgq_output_dir,
                                          output_basename = modelqg_name)
```

```{r eta-load-cv}
x <- cmdstanr::read_cmdstan_csv(c(
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-1.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-2.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-3.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-4.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-5.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-6.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-7.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-8.csv")
                                ))
draws_gen_cv_df <- as_draws_df(x$generated_quantities)
```

## Summary of model parameters (table):

The [stansummary](https://mc-stan.org/docs/cmdstan-guide/stansummary.html) function was used to report summary and diagnostic statistics over model parameters.

```{r summary-cv}
fitcv$print(variables = c("logkwHat","S1Hat","dlogkwHat","dS1Hat","beta","S2Hat","omega","rho[1,2]","sigma","alpha","sdpi"), max_rows=15)
```

## Predictions
```{r ind-pop-predictions-cv}
# 
fun_plot_ind_pop <- function(draws, .analytes_idx=analytes_idx){
  p1 <- draws %>%
  slice_sample(n=1000) %>%
  tidybayes::spread_draws(sparam_ind[i,..], sparam_pop[i,..], sS2Hat) %>%
  rename(ID=i) %>%
  left_join(analytes_names) %>%
  filter(ID %in% .analytes_idx) %>%
  tidyr::expand_grid(fi = seq(0,1,0.1)) %>%
  mutate(logkind = sparam_ind.1-sparam_ind.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  mutate(logkpop = sparam_pop.1-sparam_pop.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  ggplot() +
  ggdist::stat_lineribbon(aes(x = fi, y = logkpop), fill = "darkgray", color = "darkgray",   .width = c(.90), alpha = 1/2) +
  ggdist::stat_lineribbon(aes(x = fi, y = logkind), fill = "steelblue", color = "blue", .width = c(.90), alpha = 1/2) +
  geom_point(data = filter(data,ID %in% .analytes_idx),aes(x=fi, y=logk), size = 0.5) +
  facet_wrap(~Analyte, ncol=2)+
  theme(strip.text = element_text(size = 3)) +
  labs(x="\u03C6", y="logk (individual and population)") +
  theme(legend.position = "none") +
  coord_cartesian(xlim=c(0,1),ylim=c(-1,2))
  print(p1)
  return(p1)
}

p1<-fun_plot_ind_pop(draws_gen_cv_df,idx_analytes_out[1:10])
fun_plot_ind_pop(draws_gen_cv_df,idx_analytes_out[11:20])
fun_plot_ind_pop(draws_gen_cv_df,idx_analytes_out[21:30])
fun_plot_ind_pop(draws_gen_cv_df,idx_analytes_out[31:40])
fun_plot_ind_pop(draws_gen_cv_df,idx_analytes_out[41:50])

p2<-fun_plot_ind_pop(draws_gen_df,idx_analytes_out[1:10])
fun_plot_ind_pop(draws_gen_df,idx_analytes_out[11:20])
fun_plot_ind_pop(draws_gen_df,idx_analytes_out[21:30])
fun_plot_ind_pop(draws_gen_df,idx_analytes_out[31:40])
fun_plot_ind_pop(draws_gen_df,idx_analytes_out[41:50])

fun_plot_ind_pop(draws_gen_cv_df,idx_analytes_in[1:10])
fun_plot_ind_pop(draws_gen_cv_df,idx_analytes_in[11:20])

figure_4A <- p1 +theme(
  axis.title.x = element_text(size = 6),
  axis.title.y = element_text(size = 6),
  axis.text.x = element_text(size = 4),
  axis.text.y = element_text(size = 4),
  title = element_text(size = 7)) +
  ggtitle("no individual data")

```

# Effect of similarity - crossvalidation

```{r datastruct-cv2}
create_groupwise_cv_folds <- function(df, K = 10, seed = 42) {
  set.seed(seed)
  df$fold <- NA
  
  group_list <- split(df, df$group)
  
  for (group_name in names(group_list)) {
    group_data <- group_list[[group_name]]
    n_ids <- nrow(group_data)
    shuffled <- group_data[sample(n_ids), ]
    if (n_ids >= K) {
      folds <- rep(1:K, length.out = n_ids)
    } else {
      folds <- sample(1:K, n_ids)
    }
    shuffled$fold <- folds
    df$fold[df$id %in% shuffled$id] <- shuffled$fold
  }
  return(df)
}

K = 48

nodes <- create_groupwise_cv_folds(nodes, K, seed = 42)
tab   <- table(nodes$group, nodes$fold)

datastructcv = list()
initcv=init;

for (i in 1:K){
  
datastructcv[[i]] = datastruct;

idx_analytes_out = sort(nodes$id[nodes$fold==i])
idx_analytes_in = setdiff(unique(datastructcv[[i]]$analyte),idx_analytes_out)

idxcv =  which(datastructcv[[i]]$analyte %in% idx_analytes_in)
nObscv = length(idxcv);
datastructcv[[i]]$idxcv = idxcv;
datastructcv[[i]]$nObscv = nObscv;
}
```

```{r stan-compile-cv2, eval = FALSE}
mod50cv <- cmdstan_model(here::here(mod_model_dir, model_name_ext), stanc_options = list("O1"))
```

```{r dump-files-cv2, eval = FALSE}
for (i in 1:K){
write_stan_json(datastructcv[[i]], paste0(mod_model_dir,"/cv-data-", i, ".json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/cv-init-", i, ".json"), always_decimal = FALSE)
}
```

```{r stan-load-cv2, eval = FALSE}
mod50cvgq <- cmdstan_model(here(modgq_model_dir,modelqg_name_ext))

cv_tab = list()
for (i in 1:K){
fitcv <- cmdstanr::as_cmdstan_fit(paste0(mod_output_dir,"/",  model_name, "-cv-",  i, ".csv"))

fitcvgq  <- mod50cvgq$generate_quantities(fitcv,
                                          data = datastructcv[[i]],
                                          seed = 123,
                                          output_dir = modgq_output_dir,
                                          output_basename = paste0(modelqg_name, "-cv-", i))

draws_gen_cv_df <- as_draws_df(fitcvgq$draws(c("sparam_ind", "sparam_pop", "sS2Hat")))

cv_tab[[i]] <- draws_gen_cv_df %>%
  tidybayes::spread_draws(sparam_ind[z,..], sparam_pop[z,..], sS2Hat) %>%
  filter(z %in% nodes$id[nodes$fold==i]) %>%
  mutate(logkind = sparam_ind.1-sparam_ind.2*(1+sS2Hat)*0.5/(1+sS2Hat*0.5)) %>%
  mutate(logkpop = sparam_pop.1-sparam_pop.2*(1+sS2Hat)*0.5/(1+sS2Hat*0.5)) %>%
  group_by(z)%>%
  summarise(vlogkind = variance(logkind),
            vlogkpop = variance(logkpop))
}

df <- do.call(rbind, lapply(cv_tab, as.data.frame)) %>%
  mutate(dvar = vlogkind-vlogkpop) 

write.csv(df, file = here(data_deliv_dir,"cross_validation_results.csv"), row.names = FALSE)
```

```{r plot-cv2-results}

df = read.csv(file = here(data_deliv_dir,"cross_validation_results.csv"), header = TRUE)

df = df %>%
  mutate(rel_var_explained = (vlogkpop-vlogkind)/vlogkpop)

sim<-similarity_matrix_corrected 
diag(sim)<-0
for (i in 1:nrow(df)){
sim[i,nodes$id[nodes$fold==nodes$fold[i]]]<-0
}

maxsim<-apply(sim, 1, max)

df$maxsim = maxsim[df$z]

p1 <- df%>%
  ggplot(aes(x=rel_var_explained)) +
  geom_histogram(fill = "steelblue") +
   labs(x=" ") +
  theme(legend.position = "none") +
  xlim(-0.1,1)
p2 <- df%>%
  ggplot(aes(y = " ", x=rel_var_explained)) +
  geom_boxplot(fill = "steelblue") +
  labs(y = "", x="Variance explained") +
  theme(legend.position = "none") +
  xlim(-0.1,1)

p1/p2+plot_layout(heights = c(3, 1))


figure_5 <- df %>%
  ggplot(aes(x=maxsim, y = rel_var_explained))+
  geom_point(color = "steelblue", size = 0.5)+
  geom_smooth(se = FALSE)+
  labs(y = "Relative reduction in uncertainity", x="Maximum similarity within the hold-in set") 

figure_5

figure_5 <- figure_5+theme(
  axis.title.x = element_text(size = 8),
  axis.title.y = element_text(size = 8),
  axis.text.x = element_text(size = 7),
  axis.text.y = element_text(size = 7))

```

# Limited data predictions

Based on similarity and sigle experiment.

```{r datastruct-cv3}
datax <-  jsonlite::fromJSON(here("model/stan/mod50cv/standata.json"))
which(unique(datax$analyte) %notin% unique(datax$analyte[datax$idxcv]))
idx_analytes_out = which(unique(datax$analyte) %notin% unique(datax$analyte[datax$idxcv]))
idx_analytes_in = which(unique(datax$analyte) %in% unique(datax$analyte[datax$idxcv]))
datastructcv = datastruct;
initcv=init;

idxcv1 =  which(datastructcv$analyte %in% idx_analytes_in)
idxcv2 = datastructcv$end[idx_analytes_out]

idxcv = sort(c(idxcv1,idxcv2))
nObscv = length(idxcv);
datastructcv$idxcv = idxcv;
datastructcv$nObscv = nObscv;
```

## Fitting the model

```{r stan-compile-cv3, eval = FALSE}
mod50cv <- cmdstan_model(here::here(mod_model_dir, model_name_ext), stanc_options = list("O1"))
```

```{r dump-files-cv3, eval = FALSE}
write_stan_json(datastructcv, paste0(mod_model_dir,"/standata-limited.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-1.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-2.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-3.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-4.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-5.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-6.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-7.json"), always_decimal = FALSE)
write_stan_json(initcv(), paste0(mod_model_dir,"/init-limited-8.json"), always_decimal = FALSE)
```

```{r stan-load-cv3}
fitcvlimited <- cmdstanr::as_cmdstan_fit(c(
                                  paste0(mod_output_dir,"/",  model_name, "-limited-1.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-limited-2.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-limited-3.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-limited-4.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-limited-5.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-limited-6.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-limited-7.csv"),
                                  paste0(mod_output_dir,"/",  model_name, "-limited-8.csv")
                                ))
```

## Genereted quantitites

```{r generete-quntities-cv3, eval=FALSE}
mod50cvgq <- cmdstan_model(here(modgq_model_dir,modelqg_name_ext))
fitcvgq  <- mod50cvgq$generate_quantities(fitcvlimited,
                                          data = datastructcv,
                                          seed = 123,
                                          parallel_chains = 8,
                                          output_dir = modgq_output_dir,
                                          output_basename = paste0(modelqg_name, "-limited"))
```

```{r eta-load-cv3}
x <- cmdstanr::read_cmdstan_csv(c(
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-1.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-2.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-3.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-4.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-5.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-6.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-7.csv"),
                                  paste0(modgq_output_dir, "/",  modelqg_name, "-limited-8.csv")
                                ))
draws_gen_limited_df <- as_draws_df(x$generated_quantities)
```

## Predictions
```{r ind-pop-predictions-cv3}
# 
fun_plot_ind_pop <- function(draws, .analytes_idx=analytes_idx){
  p1 <- draws %>%
  slice_sample(n=1000) %>%
  tidybayes::spread_draws(sparam_ind[i,..], sparam_pop[i,..], sS2Hat) %>%
  rename(ID=i) %>%
  left_join(analytes_names) %>%
  filter(ID %in% .analytes_idx) %>%
  tidyr::expand_grid(fi = seq(0,1,0.1)) %>%
  mutate(logkind = sparam_ind.1-sparam_ind.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  mutate(logkpop = sparam_pop.1-sparam_pop.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  ggplot() +
  ggdist::stat_lineribbon(aes(x = fi, y = logkpop), fill = "darkgray", color = "darkgray",   .width = c(.90), alpha = 1/2) +
  ggdist::stat_lineribbon(aes(x = fi, y = logkind), fill = "steelblue", color = "blue", .width = c(.90), alpha = 1/2) +
  geom_point(data = filter(data,ID %in% .analytes_idx),aes(x=fi, y=logk), size = 0.5) +
  facet_wrap(~Analyte, ncol=2)+
  theme(strip.text = element_text(size = 3)) +
  labs(x="\u03C6", y="logk (individual and population)") +
  theme(legend.position = "none") +
  coord_cartesian(xlim=c(0,1),ylim=c(-1,2))
  print(p1)
  return(p1)
}

p1<-fun_plot_ind_pop(draws_gen_limited_df,idx_analytes_out[1:10])
fun_plot_ind_pop(draws_gen_limited_df,idx_analytes_out[11:20])
fun_plot_ind_pop(draws_gen_limited_df,idx_analytes_out[21:30])
fun_plot_ind_pop(draws_gen_limited_df,idx_analytes_out[31:40])
fun_plot_ind_pop(draws_gen_limited_df,idx_analytes_out[41:50])


figure_4B <- (p1 +theme(
  axis.title.x = element_text(size = 6),
  axis.title.y = element_text(size = 6),
  axis.text.x = element_text(size = 4),
  axis.text.y = element_text(size = 4),
  title = element_text(size = 7)) +
    ggtitle("single observation"))

figure_4 <- figure_4A + figure_4B +
  plot_annotation(tag_levels = 'A', theme = theme(plot.margin = margin()))+ plot_layout(axes = "collect")& 
  theme(plot.margin = margin(0.1, 0.1, 0.1, 0.1))  # optional: trims plot margin


```

# TOC
```{r toc}
datax <-  jsonlite::fromJSON(here("model/stan/mod50cv/standata.json"))
which(unique(datax$analyte) %notin% unique(datax$analyte[datax$idxcv]))
idx_analytes_out = which(unique(datax$analyte) %notin% unique(datax$analyte[datax$idxcv]))
idx_analytes_in = which(unique(datax$analyte) %in% unique(datax$analyte[datax$idxcv]))

sim<-similarity_matrix_corrected
diag(sim)<-0
maxsim<-apply(sim, 1, max)

idx = idx_analytes_out[1:10]
df_toc = data.frame(ID = idx, maxsim = round(maxsim[idx],3)) %>%
  arrange(maxsim) %>%
  mutate(maxsim = paste0("Similarity = ", maxsim))%>%
  left_join(analytes_names) %>%
  mutate(Analyte = str_replace_all(Analyte, "\n", " "))

df_toc = df_toc[c(1,5,10),]

dataobs = data %>%
              filter(ID %in% df_toc$ID)%>%
  mutate(Analyte = str_replace_all(Analyte, "\n", " ")) %>%
              left_join(df_toc)%>%
  mutate(Analyte2 = paste0(Analyte, "\n", maxsim))
  
tab1 <- draws_gen_cv_df %>%
  slice_sample(n=1000) %>%
  tidybayes::spread_draws(sparam_ind[i,..], sparam_pop[i,..], sS2Hat) %>%
  rename(ID=i) %>%
  filter(ID %in% df_toc$ID) %>%
  left_join(df_toc) %>%
  tidyr::expand_grid(fi = seq(0,1,0.1)) %>%
  mutate(logkind = sparam_ind.1-sparam_ind.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  mutate(logkpop = sparam_pop.1-sparam_pop.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  mutate(type = "no indiv. data")


tab2 <- draws_gen_limited_df %>%
  slice_sample(n=1000) %>%
  tidybayes::spread_draws(sparam_ind[i,..], sparam_pop[i,..], sS2Hat) %>%
  rename(ID=i) %>%
  filter(ID %in% df_toc$ID) %>%
  left_join(df_toc) %>%
  tidyr::expand_grid(fi = seq(0,1,0.1)) %>%
  mutate(logkind = sparam_ind.1-sparam_ind.2*(1+sS2Hat)*fi/(1+sS2Hat*fi)) %>%
  mutate(logkpop = sparam_pop.1-sparam_pop.2*(1+sS2Hat)*fi/(1+sS2Hat*fi))  %>%
  mutate(type = "1 observation")
   

 fig_toc <- rbind(tab1,tab2)%>%
  mutate(Analyte2 = paste0(Analyte, "\n", maxsim))%>%
  ggplot() +
  ggdist::stat_lineribbon(aes(x = fi, y = logkpop), fill = "darkgray", color = "darkgray",   .width = c(.90), alpha = 1/2) +
  ggdist::stat_lineribbon(aes(x = fi, y = logkind), fill = "steelblue", color = "blue", .width = c(.90), alpha = 1/2) +
  geom_point(data=dataobs,aes(x=fi, y=logk), size=0.25) +
  facet_grid(type~Analyte2)+
  theme_minimal(base_family = "Helvetica") +
  theme(text = element_text(size = 5), 
        strip.text = element_text(size = 5)) +
  labs(x="\u03C6", y="logk") +
  theme(legend.position = "none") +
  coord_cartesian(xlim=c(0,1),ylim=c(-1,2))


fig_toc
ggsave(here::here("deliv","figures","manuscript","main", "toc.tiff"), plot = fig_toc,
       width = 3.25, height = 1.75, units = "in",
       dpi = 300, compression = "lzw")
```

# Conclusions

The work demonstrates a general framework for integrating molecular similarity into the retention modeling workflow.

# Manuscript figures
```{r manuscript-figures}
ggsave(here::here("deliv","figures","manuscript","main", "parameter-estimates.png"),
       plot=figure_1, width = 8.46, height = 8.46*0.75, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","main", "parameter-estimates.pdf"),
       plot=figure_1, width = 8.46, height = 8.46*0.75, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","main", "parameter-estimates-fg1.png"),
       plot=figure_2, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","main", "parameter-estimates-fg1.pdf"),
       plot=figure_2, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","main", "correlations.png"),
       plot=figure_3, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","main", "correlations.pdf"),
       plot=figure_3, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","main", "predictions.png"),
       plot=figure_4, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","main", "predictions.pdf"),
       plot=figure_4, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","main", "var_explained.png"),
       plot=figure_5, width = 8.46, height = 8.46*0.75, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","main", "var_explained.pdf"),
       plot=figure_5, width = 8.46, height = 8.46*0.75, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","supplement", "parameter-estimates-fg2.png"),
       plot=figure_S2, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","supplement", "parameter-estimates-fg2.pdf"),
       plot=figure_S2, width = 8.46, height = 8.46*1.25, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","supplement", "gof.png"),
       plot=figure_S3, width = 20, height = 20, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","supplement", "gof.pdf"),
       plot=figure_S3, width = 20, height = 20, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","supplement", "iparam.png"),
       plot=figure_S4, width = 20, height = 20, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","supplement", "iparam.pdf"),
       plot=figure_S4, width = 20, height = 20, units = "cm", dpi = 300)

ggsave(here::here("deliv","figures","manuscript","supplement", "eta.png"),
       plot=figure_S5, width = 20, height = 20, units = "cm", dpi = 300)
ggsave(here::here("deliv","figures","manuscript","supplement", "eta.pdf"),
       plot=figure_S5, width = 20, height = 20, units = "cm", dpi = 300)
```

# References {.unnumbered}

::: {#refs}
:::

# Licenses {.unnumbered}

-   Code & copy; 2025, Paweł Wiczling, licensed under BSD-3.
-   Text & copy; 2025, Paweł Wiczling, licensed under CC-BY-NC 4.0.

# Original Computing Environment {.unnumbered}

```{r}
sessionInfo()
```